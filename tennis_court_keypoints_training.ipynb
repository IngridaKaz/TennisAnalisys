{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b4a6342bdd366",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget --header=\"Host: drive.usercontent.google.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\" --header=\"Accept-Language: en-US,en;q=0.9,ar;q=0.8\" --header=\"Cookie: HSID=Ag2OIHvsd2Wub4C7z; SSID=AWnBcQKwDHiTrZAU1; APISID=pltrFZgE9lJ0o1gq/AN9feEHYvs8oHd519; SAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; __Secure-1PAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; __Secure-3PAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; SID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-uttBbVDRolhF-hY16nwHXw0gACgYKAWISAQASFQHGX2MivNTw_E_toJuIRy6LMpKNOBoVAUF8yKpFSmvq7AMjvEWeNc50Zff40076; __Secure-1PSID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-utbSY2jBY1VXuw8gYl5hIO2QACgYKAXsSAQASFQHGX2MihVCJ1PwLozGqZgdSatM9QhoVAUF8yKpgrsTvI8i_UE-YHpoN7Gx-0076; __Secure-3PSID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-utwVfPl2imdPimZJ9tdDZGQAACgYKAUESAQASFQHGX2MiEJ49mV4jME2kttDAV5hwWBoVAUF8yKp80mIgju1lu-q4nI7VsFDM0076; NID=511=efI9IZpxtyJ7Dw1MAUXU8FlzS5jXGewY4Er8HliWc3A0RSWdgvNDyKY66ETjgRyTGWPbWODSmiSeYSBab5SPHVwqbJxd6ZeGW2f6BkHi61UKksXPH0CVJRM1hKpMjHPU5qw7tboM2Mi87NrosV8COB-GCLulLLbjOoSAEQewTe8NVZ5Owq8IkwvxFGfJkmUKEMkFWrw9yb5nTDl3wbZEsGFI92iEdNTSxSRovNCIPN2US-SCFdQ0m2BtvwdiWZbgnn7dSQ8yPA145Kk2BA-ATpJNJ6SJHEHLQY-9CPail9D5qgJgxR925EUg5RGCpEu9wS5xbA62KTa19wAvbAq7Dk3TWc-iX4p1s7ESFyDC7yMpFxiFPJjqkWwFi_ZfiK2TW2t0TQ60DFBxqOytQaLyHrkEvD-CQPVj6OCOP22cZY0Cu61HaAQgFO9pXH-kJUlywzVdbirJumN5gswyaQ49b3KdLcG0Jb7brOMTM24T2nGtQ10hJzsnTwX7dBk3ujqQrI_DGuURvPassPUrIZ0; AEC=Ae3NU9MOEGeKAZjP6INpOYbyMraWAWztmx5pJB_1ILu1furiTy1K37k15u0; __Secure-1PSIDTS=sidts-CjEBYfD7Z9twEKTWJ9gU7KG-rLbxJGNRQIoG3wH6JVu6yiCC2fsRrm7tN8L6d5WlILrnEAA; __Secure-3PSIDTS=sidts-CjEBYfD7Z9twEKTWJ9gU7KG-rLbxJGNRQIoG3wH6JVu6yiCC2fsRrm7tN8L6d5WlILrnEAA; 1P_JAR=2024-02-18-08; SIDCC=ABTWhQExCxkfmwCkG1RaEgz8U1ZkPeh3HmLMUdMt8S5cNSsLY5U5rAL6wlvq7dtjRw7zrtAbqsFI; __Secure-1PSIDCC=ABTWhQH0jLeRIS6Tu3LS8DXB5Q3gGDq9LTmlk60FKu795Bf0UbzsOcYWVAE96clq5aAL8i724Q0; __Secure-3PSIDCC=ABTWhQHIFcyv3nZYwp78WXEQal71jCE_ZsGT5lXs8VLr7XDIfFqHcLTIPz4HxzJb9ZnYQ5l2s9eU\" --header=\"Connection: keep-alive\" \"https://drive.usercontent.google.com/download?id=1lhAaeQCmk2y440PmagA0KmIVBIysVMwu&export=download&authuser=0&confirm=t&uuid=3077628e-fc9b-4ef2-8cde-b291040afb30&at=APZUnTU9lSikCSe3NqbxV5MVad5T%3A1708243355040\" -c -O 'tennis_court_det_dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torch import device\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import models, transforms\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99e5ef44dd0ee793",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3d9a87f43f8cbd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class KeypointsDataset(Dataset):\n",
    "    def __init__(self, img_dir, data_file):\n",
    "        self.img_dir = img_dir\n",
    "        with open(data_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img = cv2.imread(f\"{self.img_dir}/{item['id']}.png\") \n",
    "        if img is None:\n",
    "            # Handle cases where the image file might be missing\n",
    "            raise FileNotFoundError(f\"Image {self.img_dir}/{item['id']}.png not found\")\n",
    "        h,w = img.shape[:2]\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transforms(img)\n",
    "        kps = np.array(item['kps']).flatten()\n",
    "        kps = kps.astype(np.float32)\n",
    "        \n",
    "        kps[::2] *= 224.0 / w # Adjust x coordinates\n",
    "        kps[1::2] *= 224.0 / h # Adjust y coordinates\n",
    "\n",
    "        return img, kps\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8b98fc3b6dac49",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare datasets and loaders\n",
    "train_dataset = KeypointsDataset(\"tennis_court_det_dataset/data/images\", \"tennis_court_det_dataset/data/data_train.json\")\n",
    "val_dataset = KeypointsDataset(\"tennis_court_det_dataset/data/images\", \"tennis_court_det_dataset/data/data_val.json\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # Corrected train_loader to be for training data\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)      # Corrected val_loader to be for validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c420d78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a3ad90a8f7e7622",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3408f9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\kazen/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 43.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, 14*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "426ce7bf1bee2322",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Added device definition for GPU/CPU compatibility\n",
    "# model = models.resnet50(pretrained=True)\n",
    "# model.fc = torch.nn.Linear(model.fc.in_features, 14*2) #Replaces the last layer\n",
    "# model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d0dcaa30b29f0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9899841e3719161",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7399cb1054da8b0f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter 0, loss: 14964.435546875\n",
      "Epoch 0, iter 10, loss: 15036.330078125\n",
      "Epoch 0, iter 20, loss: 14660.5869140625\n",
      "Epoch 0, iter 30, loss: 13973.0556640625\n",
      "Epoch 0, iter 40, loss: 14149.6142578125\n",
      "Epoch 0, iter 50, loss: 14675.1396484375\n",
      "Epoch 0, iter 60, loss: 13833.306640625\n",
      "Epoch 0, iter 70, loss: 13859.978515625\n",
      "Epoch 0, iter 80, loss: 13501.833984375\n",
      "Epoch 0, iter 90, loss: 13473.373046875\n",
      "Epoch 0, iter 100, loss: 13853.587890625\n",
      "Epoch 0, iter 110, loss: 12924.3291015625\n",
      "Epoch 0, iter 120, loss: 13430.5341796875\n",
      "Epoch 0, iter 130, loss: 13061.7978515625\n",
      "Epoch 0, iter 140, loss: 12722.3974609375\n",
      "Epoch 0, iter 150, loss: 12209.4736328125\n",
      "Epoch 0, iter 160, loss: 12681.7333984375\n",
      "Epoch 0, iter 170, loss: 12024.9697265625\n",
      "Epoch 0, iter 180, loss: 12232.2744140625\n",
      "Epoch 0, iter 190, loss: 11770.265625\n",
      "Epoch 0, iter 200, loss: 12100.484375\n",
      "Epoch 0, iter 210, loss: 11766.8232421875\n",
      "Epoch 0, iter 220, loss: 11899.2080078125\n",
      "Epoch 0, iter 230, loss: 10961.884765625\n",
      "Epoch 0, iter 240, loss: 11704.9560546875\n",
      "Epoch 0, iter 250, loss: 10941.849609375\n",
      "Epoch 0, iter 260, loss: 10676.484375\n",
      "Epoch 0, iter 270, loss: 11026.615234375\n",
      "Epoch 0, iter 280, loss: 10485.123046875\n",
      "Epoch 0, iter 290, loss: 10448.3505859375\n",
      "Epoch 0, iter 300, loss: 10795.3916015625\n",
      "Epoch 0, iter 310, loss: 10627.0\n",
      "Epoch 0, iter 320, loss: 11831.5517578125\n",
      "Epoch 0, iter 330, loss: 10876.1640625\n",
      "Epoch 0, iter 340, loss: 10330.4619140625\n",
      "Epoch 0, iter 350, loss: 9743.1923828125\n",
      "Epoch 0, iter 360, loss: 9306.4775390625\n",
      "Epoch 0, iter 370, loss: 9267.181640625\n",
      "Epoch 0, iter 380, loss: 9304.578125\n",
      "Epoch 0, iter 390, loss: 9027.1025390625\n",
      "Epoch 0, iter 400, loss: 9245.275390625\n",
      "Epoch 0, iter 410, loss: 9243.9541015625\n",
      "Epoch 0, iter 420, loss: 8590.638671875\n",
      "Epoch 0, iter 430, loss: 9269.640625\n",
      "Epoch 0, iter 440, loss: 8588.2998046875\n",
      "Epoch 0, iter 450, loss: 8270.8310546875\n",
      "Epoch 0, iter 460, loss: 9001.802734375\n",
      "Epoch 0, iter 470, loss: 8123.61572265625\n",
      "Epoch 0, iter 480, loss: 8526.37109375\n",
      "Epoch 0, iter 490, loss: 8083.95458984375\n",
      "Epoch 0, iter 500, loss: 8360.6943359375\n",
      "Epoch 0, iter 510, loss: 8121.51025390625\n",
      "Epoch 0, iter 520, loss: 7782.26220703125\n",
      "Epoch 0, iter 530, loss: 7298.0869140625\n",
      "Epoch 0, iter 540, loss: 7180.9091796875\n",
      "Epoch 0, iter 550, loss: 7418.37060546875\n",
      "Epoch 0, iter 560, loss: 7308.80126953125\n",
      "Epoch 0, iter 570, loss: 7188.3505859375\n",
      "Epoch 0, iter 580, loss: 7140.01025390625\n",
      "Epoch 0, iter 590, loss: 7113.49267578125\n",
      "Epoch 0, iter 600, loss: 7099.14599609375\n",
      "Epoch 0, iter 610, loss: 6909.59765625\n",
      "Epoch 0, iter 620, loss: 6895.91552734375\n",
      "Epoch 0, iter 630, loss: 6399.39794921875\n",
      "Epoch 0, iter 640, loss: 6514.88525390625\n",
      "Epoch 0, iter 650, loss: 6264.11865234375\n",
      "Epoch 0, iter 660, loss: 6222.75439453125\n",
      "Epoch 0, iter 670, loss: 6703.1005859375\n",
      "Epoch 0, iter 680, loss: 6308.10986328125\n",
      "Epoch 0, iter 690, loss: 5689.2880859375\n",
      "Epoch 0, iter 700, loss: 5872.22607421875\n",
      "Epoch 0, iter 710, loss: 5388.44384765625\n",
      "Epoch 0, iter 720, loss: 5455.0537109375\n",
      "Epoch 0, iter 730, loss: 5713.7763671875\n",
      "Epoch 0, iter 740, loss: 5763.8349609375\n",
      "Epoch 0, iter 750, loss: 5627.8115234375\n",
      "Epoch 0, iter 760, loss: 5841.40771484375\n",
      "Epoch 0, iter 770, loss: 5818.65380859375\n",
      "Epoch 0, iter 780, loss: 5378.62158203125\n",
      "Epoch 0, iter 790, loss: 5004.11572265625\n",
      "Epoch 0, iter 800, loss: 4871.88330078125\n",
      "Epoch 0, iter 810, loss: 4709.26953125\n",
      "Epoch 0, iter 820, loss: 5831.96337890625\n",
      "Epoch 1, iter 0, loss: 4525.19384765625\n",
      "Epoch 1, iter 10, loss: 4850.0234375\n",
      "Epoch 1, iter 20, loss: 4516.283203125\n",
      "Epoch 1, iter 30, loss: 4338.74951171875\n",
      "Epoch 1, iter 40, loss: 4555.3583984375\n",
      "Epoch 1, iter 50, loss: 4573.65478515625\n",
      "Epoch 1, iter 60, loss: 4549.15234375\n",
      "Epoch 1, iter 70, loss: 4148.2578125\n",
      "Epoch 1, iter 80, loss: 4250.48583984375\n",
      "Epoch 1, iter 90, loss: 3928.224365234375\n",
      "Epoch 1, iter 100, loss: 4288.98681640625\n",
      "Epoch 1, iter 110, loss: 3682.651611328125\n",
      "Epoch 1, iter 120, loss: 3642.571533203125\n",
      "Epoch 1, iter 130, loss: 3871.066650390625\n",
      "Epoch 1, iter 140, loss: 3671.484375\n",
      "Epoch 1, iter 150, loss: 3835.200439453125\n",
      "Epoch 1, iter 160, loss: 3620.115966796875\n",
      "Epoch 1, iter 170, loss: 3935.671142578125\n",
      "Epoch 1, iter 180, loss: 3956.68310546875\n",
      "Epoch 1, iter 190, loss: 3340.231201171875\n",
      "Epoch 1, iter 200, loss: 3154.406982421875\n",
      "Epoch 1, iter 210, loss: 3385.73046875\n",
      "Epoch 1, iter 220, loss: 3162.03515625\n",
      "Epoch 1, iter 230, loss: 3195.32373046875\n",
      "Epoch 1, iter 240, loss: 3133.962890625\n",
      "Epoch 1, iter 250, loss: 2990.25048828125\n",
      "Epoch 1, iter 260, loss: 2771.48583984375\n",
      "Epoch 1, iter 270, loss: 2812.025146484375\n",
      "Epoch 1, iter 280, loss: 2636.91162109375\n",
      "Epoch 1, iter 290, loss: 3508.7734375\n",
      "Epoch 1, iter 300, loss: 2811.65283203125\n",
      "Epoch 1, iter 310, loss: 2658.328857421875\n",
      "Epoch 1, iter 320, loss: 2528.056884765625\n",
      "Epoch 1, iter 330, loss: 2649.216796875\n",
      "Epoch 1, iter 340, loss: 2572.229248046875\n",
      "Epoch 1, iter 350, loss: 2426.322998046875\n",
      "Epoch 1, iter 360, loss: 2846.182373046875\n",
      "Epoch 1, iter 370, loss: 2506.635009765625\n",
      "Epoch 1, iter 380, loss: 2273.459228515625\n",
      "Epoch 1, iter 390, loss: 2590.06884765625\n",
      "Epoch 1, iter 400, loss: 2193.887451171875\n",
      "Epoch 1, iter 410, loss: 2023.2183837890625\n",
      "Epoch 1, iter 420, loss: 2181.037841796875\n",
      "Epoch 1, iter 430, loss: 2039.23828125\n",
      "Epoch 1, iter 440, loss: 2140.10498046875\n",
      "Epoch 1, iter 450, loss: 2167.67822265625\n",
      "Epoch 1, iter 460, loss: 1996.159912109375\n",
      "Epoch 1, iter 470, loss: 1739.6636962890625\n",
      "Epoch 1, iter 480, loss: 1849.8685302734375\n",
      "Epoch 1, iter 490, loss: 1911.773681640625\n",
      "Epoch 1, iter 500, loss: 1748.5010986328125\n",
      "Epoch 1, iter 510, loss: 1755.869384765625\n",
      "Epoch 1, iter 520, loss: 1652.675537109375\n",
      "Epoch 1, iter 530, loss: 1652.9256591796875\n",
      "Epoch 1, iter 540, loss: 1667.336181640625\n",
      "Epoch 1, iter 550, loss: 1581.0885009765625\n",
      "Epoch 1, iter 560, loss: 1603.2686767578125\n",
      "Epoch 1, iter 570, loss: 1704.455078125\n",
      "Epoch 1, iter 580, loss: 1434.7564697265625\n",
      "Epoch 1, iter 590, loss: 1652.426025390625\n",
      "Epoch 1, iter 600, loss: 1463.7930908203125\n",
      "Epoch 1, iter 610, loss: 1365.0162353515625\n",
      "Epoch 1, iter 620, loss: 1283.956787109375\n",
      "Epoch 1, iter 630, loss: 1371.0509033203125\n",
      "Epoch 1, iter 640, loss: 1507.038330078125\n",
      "Epoch 1, iter 650, loss: 1242.4361572265625\n",
      "Epoch 1, iter 660, loss: 1869.0050048828125\n",
      "Epoch 1, iter 670, loss: 1210.8759765625\n",
      "Epoch 1, iter 680, loss: 1044.5050048828125\n",
      "Epoch 1, iter 690, loss: 1190.6612548828125\n",
      "Epoch 1, iter 700, loss: 1178.2276611328125\n",
      "Epoch 1, iter 710, loss: 1213.8253173828125\n",
      "Epoch 1, iter 720, loss: 1029.7698974609375\n",
      "Epoch 1, iter 730, loss: 1021.2183227539062\n",
      "Epoch 1, iter 740, loss: 1000.5040893554688\n",
      "Epoch 1, iter 750, loss: 933.2966918945312\n",
      "Epoch 1, iter 760, loss: 974.2301025390625\n",
      "Epoch 1, iter 770, loss: 862.6766357421875\n",
      "Epoch 1, iter 780, loss: 930.7781982421875\n",
      "Epoch 1, iter 790, loss: 784.0503540039062\n",
      "Epoch 1, iter 800, loss: 977.5806274414062\n",
      "Epoch 1, iter 810, loss: 730.0816650390625\n",
      "Epoch 1, iter 820, loss: 868.0888061523438\n",
      "Epoch 2, iter 0, loss: 791.3714599609375\n",
      "Epoch 2, iter 10, loss: 740.12451171875\n",
      "Epoch 2, iter 20, loss: 793.8875732421875\n",
      "Epoch 2, iter 30, loss: 736.7449340820312\n",
      "Epoch 2, iter 40, loss: 790.1409912109375\n",
      "Epoch 2, iter 50, loss: 783.1627807617188\n",
      "Epoch 2, iter 60, loss: 650.12890625\n",
      "Epoch 2, iter 70, loss: 844.7571411132812\n",
      "Epoch 2, iter 80, loss: 628.8305053710938\n",
      "Epoch 2, iter 90, loss: 616.3541259765625\n",
      "Epoch 2, iter 100, loss: 774.6510009765625\n",
      "Epoch 2, iter 110, loss: 667.9595947265625\n",
      "Epoch 2, iter 120, loss: 585.7726440429688\n",
      "Epoch 2, iter 130, loss: 617.4659423828125\n",
      "Epoch 2, iter 140, loss: 474.54095458984375\n",
      "Epoch 2, iter 150, loss: 449.7236633300781\n",
      "Epoch 2, iter 160, loss: 540.9844360351562\n",
      "Epoch 2, iter 170, loss: 473.24322509765625\n",
      "Epoch 2, iter 180, loss: 471.6390686035156\n",
      "Epoch 2, iter 190, loss: 509.8756408691406\n",
      "Epoch 2, iter 200, loss: 499.9649963378906\n",
      "Epoch 2, iter 210, loss: 565.1778564453125\n",
      "Epoch 2, iter 220, loss: 430.3465270996094\n",
      "Epoch 2, iter 230, loss: 618.6585083007812\n",
      "Epoch 2, iter 240, loss: 578.8546752929688\n",
      "Epoch 2, iter 250, loss: 415.4091491699219\n",
      "Epoch 2, iter 260, loss: 448.9803771972656\n",
      "Epoch 2, iter 270, loss: 487.95013427734375\n",
      "Epoch 2, iter 280, loss: 412.23284912109375\n",
      "Epoch 2, iter 290, loss: 346.9580993652344\n",
      "Epoch 2, iter 300, loss: 288.4045104980469\n",
      "Epoch 2, iter 310, loss: 705.5283203125\n",
      "Epoch 2, iter 320, loss: 295.5592346191406\n",
      "Epoch 2, iter 330, loss: 289.8612365722656\n",
      "Epoch 2, iter 340, loss: 290.0324401855469\n",
      "Epoch 2, iter 350, loss: 253.02516174316406\n",
      "Epoch 2, iter 360, loss: 308.0492858886719\n",
      "Epoch 2, iter 370, loss: 387.93896484375\n",
      "Epoch 2, iter 380, loss: 306.16839599609375\n",
      "Epoch 2, iter 390, loss: 245.12051391601562\n",
      "Epoch 2, iter 400, loss: 272.6195983886719\n",
      "Epoch 2, iter 410, loss: 263.77520751953125\n",
      "Epoch 2, iter 420, loss: 234.94015502929688\n",
      "Epoch 2, iter 430, loss: 233.34107971191406\n",
      "Epoch 2, iter 440, loss: 254.414306640625\n",
      "Epoch 2, iter 450, loss: 267.12152099609375\n",
      "Epoch 2, iter 460, loss: 379.97705078125\n",
      "Epoch 2, iter 470, loss: 225.93251037597656\n",
      "Epoch 2, iter 480, loss: 191.76185607910156\n",
      "Epoch 2, iter 490, loss: 215.11537170410156\n",
      "Epoch 2, iter 500, loss: 178.3504180908203\n",
      "Epoch 2, iter 510, loss: 174.1696319580078\n",
      "Epoch 2, iter 520, loss: 184.53208923339844\n",
      "Epoch 2, iter 530, loss: 201.7793731689453\n",
      "Epoch 2, iter 540, loss: 128.06854248046875\n",
      "Epoch 2, iter 550, loss: 199.0574493408203\n",
      "Epoch 2, iter 560, loss: 192.31103515625\n",
      "Epoch 2, iter 570, loss: 173.0777130126953\n",
      "Epoch 2, iter 580, loss: 178.91653442382812\n",
      "Epoch 2, iter 590, loss: 165.47557067871094\n",
      "Epoch 2, iter 600, loss: 856.8082885742188\n",
      "Epoch 2, iter 610, loss: 340.3876037597656\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m kps \u001b[38;5;241m=\u001b[39m kps\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, kps)\n\u001b[0;32m      9\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torchvision\\models\\densenet.py:213\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 213\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(features, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    215\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(out, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torchvision\\models\\densenet.py:122\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[1;34m(self, init_features)\u001b[0m\n\u001b[0;32m    120\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 122\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torchvision\\models\\densenet.py:88\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     86\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_checkpoint_bottleneck(prev_features)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(bottleneck_output)))\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torchvision\\models\\densenet.py:49\u001b[0m, in \u001b[0;36m_DenseLayer.bn_function\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbn_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     48\u001b[0m     concated_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(inputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcated_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: T484\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bottleneck_output\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kazen\\miniconda3\\envs\\tennisEnv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i, (imgs,kps) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        kps = kps.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, kps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, iter {i}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"keypoints_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
